{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc266e6-9cee-4ae5-9c4d-1362054e69d3",
   "metadata": {},
   "source": [
    "### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "**Min-Max scaling** is a normalization technique used in data preprocessing to transform features to a specific range, typically [0, 1]. This technique helps ensure that different features contribute equally to the model's performance, especially in algorithms that rely on distance calculations.\n",
    "\n",
    "**How it works**: The Min-Max scaling formula is given by:\n",
    "\n",
    "\\[ \n",
    "X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} \n",
    "\\]\n",
    "\n",
    "where \\(X\\) is the original value, \\(X_{\\text{min}}\\) is the minimum value of the feature, and \\(X_{\\text{max}}\\) is the maximum value of the feature.\n",
    "\n",
    "**Example**: For a dataset with values [1, 5, 10, 15, 20]:\n",
    "\n",
    "1. Minimum value \\(X_{\\text{min}} = 1\\)\n",
    "2. Maximum value \\(X_{\\text{max}} = 20\\)\n",
    "\n",
    "Transforming the value 10:\n",
    "\n",
    "\\[ \n",
    "X' = \\frac{10 - 1}{20 - 1} = \\frac{9}{19} \\approx 0.474 \n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe14ca-8b30-4f8d-858e-863aa7479d26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e94c9c-358d-4128-99be-b40e79064461",
   "metadata": {},
   "source": [
    "### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "\n",
    "The **Unit Vector technique** (also known as vector normalization or scaling to unit length) transforms features so that they have a length (or magnitude) of 1. This is done by dividing each feature value by the Euclidean norm (L2 norm) of the feature vector.\n",
    "\n",
    "**How it works**: The formula for unit vector scaling is:\n",
    "\n",
    "\\[ \n",
    "X' = \\frac{X}{\\|X\\|} \n",
    "\\]\n",
    "\n",
    "where \\(\\|X\\|\\) is the Euclidean norm of the feature vector.\n",
    "\n",
    "**Difference from Min-Max Scaling**: While Min-Max scaling transforms values to a specific range (e.g., [0, 1]), the Unit Vector technique focuses on the relative proportions of feature values and scales them based on their magnitude.\n",
    "\n",
    "**Example**: For a feature vector [3, 4]:\n",
    "\n",
    "1. Calculate the Euclidean norm:\n",
    "\n",
    "\\[ \n",
    "\\|X\\| = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = 5 \n",
    "\\]\n",
    "\n",
    "2. Transforming the values:\n",
    "\n",
    "\\[ \n",
    "X' = \\left[\\frac{3}{5}, \\frac{4}{5}\\right] = [0.6, 0.8] \n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dccedf9-05b9-433d-a27e-7ac937a7ab53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a1c8651-55ff-4187-b818-35a4be783801",
   "metadata": {},
   "source": [
    "### Q3. What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
    "\n",
    "**Principal Component Analysis (PCA)** is a statistical technique used for dimensionality reduction while preserving as much variance as possible. PCA transforms the original features into a new set of orthogonal features called principal components, which capture the maximum variance in the data.\n",
    "\n",
    "**How it works**:\n",
    "1. Standardize the dataset.\n",
    "2. Compute the covariance matrix.\n",
    "3. Calculate the eigenvalues and eigenvectors of the covariance matrix.\n",
    "4. Sort the eigenvalues and select the top k eigenvectors to form the principal components.\n",
    "\n",
    "**Example**: Given a dataset with two features (height and weight), PCA might transform them into a single principal component that captures the most variance. If the original features are highly correlated, PCA can effectively reduce the dimensions while maintaining essential information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9911141-0a34-4c02-96bc-a0a92dbcaa98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c0e39c-caad-4df9-8014-8151abaa20f0",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "**Relationship**: PCA is a powerful method for feature extraction because it identifies the most informative features in a dataset by capturing the directions of maximum variance. \n",
    "\n",
    "**Using PCA for Feature Extraction**: \n",
    "- By applying PCA, we can reduce the number of features in the dataset while retaining the most important information.\n",
    "- The principal components obtained from PCA can be used as new features for modeling.\n",
    "\n",
    "**Example**: In a dataset with multiple features like age, income, and spending score, PCA could extract two principal components that represent the most variance. Instead of using all original features, we can use these two principal components for subsequent modeling, which simplifies the model and reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92169c21-b150-4303-8710-e31e11ff396e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e97891-9126-49d4-a8e9-b8813593bd4a",
   "metadata": {},
   "source": [
    "### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
    "\n",
    "In building a recommendation system for a food delivery service, Min-Max scaling would be applied as follows:\n",
    "\n",
    "1. **Identify Features**: Determine the numerical features to scale, such as price, rating, and delivery time.\n",
    "2. **Calculate Min-Max**: For each feature, calculate the minimum and maximum values.\n",
    "3. **Apply Scaling**: Transform each feature using the Min-Max scaling formula to ensure all features are within the same range (e.g., [0, 1]). This ensures that the model treats each feature equally without bias towards features with larger scales.\n",
    "4. **Build the Model**: Use the scaled features to train the recommendation model, improving the effectiveness of distance-based algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52976e0-00ff-48c2-b9e6-f526176c8a4b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b5ddffb-ed9a-4c47-8c44-23ab921f24bc",
   "metadata": {},
   "source": [
    "### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
    "\n",
    "To use PCA for reducing dimensionality in a stock price prediction project:\n",
    "\n",
    "1. **Preprocess Data**: Standardize the features to have zero mean and unit variance, ensuring that PCA is not biased toward features with larger scales.\n",
    "2. **Compute Covariance Matrix**: Calculate the covariance matrix of the standardized data to understand feature relationships.\n",
    "3. **Perform PCA**: Extract the eigenvalues and eigenvectors, sort them, and select the top k components that explain the most variance (e.g., 95% of the total variance).\n",
    "4. **Transform Dataset**: Project the original dataset onto the selected principal components, reducing the number of features while retaining critical information.\n",
    "5. **Build the Model**: Use the transformed dataset with reduced dimensions for training the prediction model, improving computational efficiency and potentially enhancing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf3a23-2f29-4f6f-bf37-b658fe70a199",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e7cad7-2ece-4d93-b0ad-fe1f349695d6",
   "metadata": {},
   "source": [
    "### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n",
    "\n",
    "To perform Min-Max scaling to a range of -1 to 1:\n",
    "\n",
    "1. **Identify Min and Max**: \n",
    "   - \\(X_{\\text{min}} = 1\\)\n",
    "   - \\(X_{\\text{max}} = 20\\)\n",
    "\n",
    "2. **Apply Transformation**:\n",
    "The formula for scaling to a range [a, b] is:\n",
    "\n",
    "\\[ \n",
    "X' = a + \\frac{(X - X_{\\text{min}})(b - a)}{X_{\\text{max}} - X_{\\text{min}}} \n",
    "\\]\n",
    "\n",
    "For the range [-1, 1], we set \\(a = -1\\) and \\(b = 1\\):\n",
    "\n",
    "\\[ \n",
    "X' = -1 + \\frac{(X - 1)(1 - (-1))}{20 - 1} \n",
    "\\]\n",
    "\n",
    "Calculating for each value:\n",
    "\n",
    "- For 1: \n",
    "\\[ \n",
    "X' = -1 + \\frac{(1 - 1)(2)}{19} = -1 \n",
    "\\]\n",
    "- For 5: \n",
    "\\[ \n",
    "X' = -1 + \\frac{(5 - 1)(2)}{19} \\approx -0.578 \n",
    "\\]\n",
    "- For 10: \n",
    "\\[ \n",
    "X' = -1 + \\frac{(10 - 1)(2)}{19} \\approx -0.052 \n",
    "\\]\n",
    "- For 15: \n",
    "\\[ \n",
    "X' = -1 + \\frac{(15 - 1)(2)}{19} \\approx 0.474 \n",
    "\\]\n",
    "- For 20: \n",
    "\\[ \n",
    "X' = -1 + \\frac{(20 - 1)(2)}{19} = 1 \n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479cf3f-4027-4cd1-874e-ada2c2c4f8f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93de0a25-9081-4ed8-ac26-14737a39dcda",
   "metadata": {},
   "source": [
    "### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "In performing Feature Extraction using PCA on the dataset [height, weight, age, gender, blood pressure]:\n",
    "\n",
    "1. **Preprocessing**: Standardize the features, especially numerical ones like height, weight, age, and blood pressure. Convert categorical features (gender) into numerical format (e.g., one-hot encoding).\n",
    "\n",
    "2. **PCA Execution**: After applying PCA, calculate the explained variance ratio for each principal component.\n",
    "\n",
    "3. **Choosing Components**: Typically, you would choose enough principal components to explain a substantial amount of variance (e.g., 90-95%). This decision can be based on a cumulative explained variance plot.\n",
    "\n",
    "**Conclusion**: The number of principal components to retain would depend on the cumulative explained variance. If the first three principal components explain 95% of the variance, I would retain those three for further analysis, as they capture the most significant patterns in the data while reducing dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034b413-fe38-464a-bf93-cb756ba20671",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
